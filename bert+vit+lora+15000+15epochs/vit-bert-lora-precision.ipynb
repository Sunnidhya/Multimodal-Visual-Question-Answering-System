{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-16T02:14:07.620195Z","iopub.execute_input":"2024-05-16T02:14:07.620622Z","iopub.status.idle":"2024-05-16T02:14:09.309674Z","shell.execute_reply.started":"2024-05-16T02:14:07.620586Z","shell.execute_reply":"2024-05-16T02:14:09.308767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#this code loads the first 200 examples from the validation split of the \n#\"HuggingFaceM4/VQAv2\" dataset into the variable named dataset.\n\nfrom datasets import load_dataset\n\n# dataset = load_dataset(\"HuggingFaceM4/VQAv2\")\ndataset = load_dataset(\"HuggingFaceM4/VQAv2\", split=[\"train[:25%]\", \"validation[:25%]\"])\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:14:20.940988Z","iopub.execute_input":"2024-05-16T02:14:20.941785Z","iopub.status.idle":"2024-05-16T02:34:58.470481Z","shell.execute_reply.started":"2024-05-16T02:14:20.941736Z","shell.execute_reply":"2024-05-16T02:34:58.469396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Access the train split\ntrain_dataset = dataset[0]\n\n# Print the first row\nprint(train_dataset[0])","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:35:35.762213Z","iopub.execute_input":"2024-05-16T02:35:35.762715Z","iopub.status.idle":"2024-05-16T02:35:35.836167Z","shell.execute_reply.started":"2024-05-16T02:35:35.762682Z","shell.execute_reply":"2024-05-16T02:35:35.835220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset[0]['image']","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:35:40.175524Z","iopub.execute_input":"2024-05-16T02:35:40.175874Z","iopub.status.idle":"2024-05-16T02:35:40.286421Z","shell.execute_reply.started":"2024-05-16T02:35:40.175848Z","shell.execute_reply":"2024-05-16T02:35:40.285496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Access the validation split\nvalidation_dataset = dataset[1]\n\n# Print the first row\nprint(validation_dataset[0])","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:35:47.073104Z","iopub.execute_input":"2024-05-16T02:35:47.073955Z","iopub.status.idle":"2024-05-16T02:35:47.097505Z","shell.execute_reply.started":"2024-05-16T02:35:47.073923Z","shell.execute_reply":"2024-05-16T02:35:47.096180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_dataset[0]['image']","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:35:58.964525Z","iopub.execute_input":"2024-05-16T02:35:58.964917Z","iopub.status.idle":"2024-05-16T02:35:59.060737Z","shell.execute_reply.started":"2024-05-16T02:35:58.964888Z","shell.execute_reply":"2024-05-16T02:35:59.059723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing image","metadata":{}},{"cell_type":"code","source":"#Read only the Answer space from this model (labels and the config file)\nfrom transformers import ViltConfig\nconfig = ViltConfig.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:36:04.938546Z","iopub.execute_input":"2024-05-16T02:36:04.938899Z","iopub.status.idle":"2024-05-16T02:36:16.023304Z","shell.execute_reply.started":"2024-05-16T02:36:04.938872Z","shell.execute_reply":"2024-05-16T02:36:16.022389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(config.id2label)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:36:18.848969Z","iopub.execute_input":"2024-05-16T02:36:18.850174Z","iopub.status.idle":"2024-05-16T02:36:18.856711Z","shell.execute_reply.started":"2024-05-16T02:36:18.850139Z","shell.execute_reply":"2024-05-16T02:36:18.855651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:36:20.795844Z","iopub.execute_input":"2024-05-16T02:36:20.796561Z","iopub.status.idle":"2024-05-16T02:36:20.802843Z","shell.execute_reply.started":"2024-05-16T02:36:20.796528Z","shell.execute_reply":"2024-05-16T02:36:20.801835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(validation_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:36:22.912703Z","iopub.execute_input":"2024-05-16T02:36:22.913080Z","iopub.status.idle":"2024-05-16T02:36:22.919807Z","shell.execute_reply.started":"2024-05-16T02:36:22.913049Z","shell.execute_reply":"2024-05-16T02:36:22.918734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\n\ndef get_score(count: int) -> float:\n    return min(1.0, count / 3)\n\ndef add_labels_scores(annotation):\n\n    if(annotation['answers'] != None):\n        answers = annotation['answers']\n        answer_count = {}\n        for answer in answers:\n            answer_ = answer[\"answer\"]\n            answer_count[answer_] = answer_count.get(answer_, 0) + 1\n        labels = []\n        scores = []\n        for answer in answer_count:\n            if answer not in config.label2id:\n                continue\n            labels.append(config.label2id[answer])\n            score = get_score(answer_count[answer])\n            scores.append(score)\n        annotation['labels'] = labels\n        annotation['scores'] = scores\n \n    return annotation\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:36:24.461428Z","iopub.execute_input":"2024-05-16T02:36:24.462262Z","iopub.status.idle":"2024-05-16T02:36:24.470100Z","shell.execute_reply.started":"2024-05-16T02:36:24.462234Z","shell.execute_reply":"2024-05-16T02:36:24.469000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport numpy as np\nfrom IPython.display import display\n\n\n#This is not the subsetting, so we take the whole train, the subsetting happens way below\nnum_samples_to_display = len(train_dataset)\nsubset_train = train_dataset.select(range(num_samples_to_display))","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:36:26.427218Z","iopub.execute_input":"2024-05-16T02:36:26.427929Z","iopub.status.idle":"2024-05-16T02:36:26.437707Z","shell.execute_reply.started":"2024-05-16T02:36:26.427892Z","shell.execute_reply":"2024-05-16T02:36:26.436552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport numpy as np\nfrom IPython.display import display\n\n#This is not the subsetting, so we take the whole validation, the subsetting happens way below\nnum_samples_to_display = len(validation_dataset)\nsubset_val = validation_dataset.select(range(num_samples_to_display))","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:36:27.776281Z","iopub.execute_input":"2024-05-16T02:36:27.776673Z","iopub.status.idle":"2024-05-16T02:36:27.786925Z","shell.execute_reply.started":"2024-05-16T02:36:27.776644Z","shell.execute_reply":"2024-05-16T02:36:27.785874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def showImage(istrain=True, id=None):\n    if istrain:\n        data = subset_train\n    else:\n        data = subset_val\n    if id == None:\n        id = np.random.randint(len(data))\n    \n    modified_item = add_labels_scores(data[id])\n    #print(f\"Sample {id}: {modified_item}\\n\")\n    image = modified_item['image']\n\n    print(image)\n    display(image)\n\n    print(\"Question:\\t\", modified_item[\"question\"])\n    print(\"Answer:\\t\", modified_item[\"answers\"])\n    print(\"Labels:\\t\", modified_item[\"labels\"])\n    print(\"Scores:\\t\", modified_item[\"scores\"])\n    print(\"Scores for these labels:\\t\",[config.id2label[label] for label in modified_item[\"labels\"]])","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:36:28.976217Z","iopub.execute_input":"2024-05-16T02:36:28.977092Z","iopub.status.idle":"2024-05-16T02:36:28.984017Z","shell.execute_reply.started":"2024-05-16T02:36:28.977044Z","shell.execute_reply":"2024-05-16T02:36:28.983095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"showImage(True)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:36:30.890866Z","iopub.execute_input":"2024-05-16T02:36:30.891510Z","iopub.status.idle":"2024-05-16T02:36:31.068818Z","shell.execute_reply.started":"2024-05-16T02:36:30.891470Z","shell.execute_reply":"2024-05-16T02:36:31.067847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"showImage(False)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:36:33.594381Z","iopub.execute_input":"2024-05-16T02:36:33.594885Z","iopub.status.idle":"2024-05-16T02:36:33.707177Z","shell.execute_reply.started":"2024-05-16T02:36:33.594852Z","shell.execute_reply":"2024-05-16T02:36:33.706226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom PIL import Image\n\nclass VQADataset(torch.utils.data.Dataset):\n    \"\"\"VQA (v2) dataset.\"\"\"\n\n    def __init__(self, questions, annotations, preprocessor,tokenizer):\n        self.questions = questions\n        self.annotations = annotations\n        self.preprocessor = preprocessor\n        self.tokenizer=tokenizer\n\n    def __len__(self):\n        return len(self.annotations)\n\n    def __getitem__(self, idx):\n        # get image + text\n        annotations = self.annotations[idx]\n        questions = self.questions[idx]\n        image = annotations['image']\n        image = image.convert(\"RGB\")  # Explicitly convert the PIL Image object to RGB mode        \n        image = np.array(image)\n        text = questions['question']\n        \n        encoding = self.preprocessor(image, return_tensors=\"pt\")\n        encoded_text = self.tokenizer(\n            text=text,\n            padding='max_length',\n            max_length=24,\n            truncation=True,\n            return_tensors='pt',\n            return_token_type_ids=True,\n            return_attention_mask=True,\n        )\n\n        encoding [\"input_ids\"]= encoded_text['input_ids']\n        encoding [\"token_type_ids\"]= encoded_text['token_type_ids']\n        encoding [\"attention_mask\"]= encoded_text['attention_mask']\n\n\n        # remove batch dimension\n        for k,v in encoding.items():\n          encoding[k] = v.squeeze()\n        # add labels\n        labels = annotations['labels']\n        scores = annotations['scores']\n        # based on: https://github.com/dandelin/ViLT/blob/762fd3975c180db6fc88f577cf39549983fa373a/vilt/modules/objectives.py#L301\n        targets = torch.zeros(len(config.id2label))\n        for label, score in zip(labels, scores):\n              targets[label] = score\n        encoding[\"labels\"] = targets\n\n        return encoding\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:36:35.397017Z","iopub.execute_input":"2024-05-16T02:36:35.397790Z","iopub.status.idle":"2024-05-16T02:36:35.410533Z","shell.execute_reply.started":"2024-05-16T02:36:35.397756Z","shell.execute_reply":"2024-05-16T02:36:35.409485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Subsetting","metadata":{}},{"cell_type":"code","source":"import random\n\n# Specify the number of samples you want to use\nnum_samples = 15000\n\n# Randomly sample indices for our subset\nindices = random.sample(range(len(subset_train)), num_samples)\n\n# Create subset from the sampled indices\nsubset_questions = [{'question': subset_train[i]['question']} for i in indices]\nsubset_annotations = [add_labels_scores(subset_train[i]) for i in indices]","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:36:39.370648Z","iopub.execute_input":"2024-05-16T02:36:39.371403Z","iopub.status.idle":"2024-05-16T02:36:50.616910Z","shell.execute_reply.started":"2024-05-16T02:36:39.371368Z","shell.execute_reply":"2024-05-16T02:36:50.615600Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Specify the number of samples you want to use\nnum_samples = 3000\n\n# Randomly sample indices for our subset\nval_indices = random.sample(range(len(subset_val)), num_samples)\nsubset_val_questions = [{'question': subset_val[i]['question']} for i in val_indices]\nsubset_val_annotations = [add_labels_scores(subset_val[i]) for i in val_indices]","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:36:53.351436Z","iopub.execute_input":"2024-05-16T02:36:53.351857Z","iopub.status.idle":"2024-05-16T02:37:04.439977Z","shell.execute_reply.started":"2024-05-16T02:36:53.351825Z","shell.execute_reply":"2024-05-16T02:37:04.439145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(subset_questions[0])\nprint(subset_annotations[0])\n     ","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:37:06.377065Z","iopub.execute_input":"2024-05-16T02:37:06.377819Z","iopub.status.idle":"2024-05-16T02:37:06.382949Z","shell.execute_reply.started":"2024-05-16T02:37:06.377787Z","shell.execute_reply":"2024-05-16T02:37:06.381998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(subset_val_questions[0])\nprint(subset_val_annotations[0])","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:37:08.174617Z","iopub.execute_input":"2024-05-16T02:37:08.174999Z","iopub.status.idle":"2024-05-16T02:37:08.181016Z","shell.execute_reply.started":"2024-05-16T02:37:08.174969Z","shell.execute_reply":"2024-05-16T02:37:08.179829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer,AutoFeatureExtractor\ntext='bert-base-uncased'\nimage='google/vit-base-patch16-224-in21k'\ntokenizer = AutoTokenizer.from_pretrained(text)\npreprocessor=AutoFeatureExtractor.from_pretrained(image)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:37:09.350855Z","iopub.execute_input":"2024-05-16T02:37:09.351249Z","iopub.status.idle":"2024-05-16T02:37:27.029111Z","shell.execute_reply.started":"2024-05-16T02:37:09.351219Z","shell.execute_reply":"2024-05-16T02:37:27.028087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vqa2_dataset = VQADataset(questions=subset_questions,\n                     annotations=subset_annotations,\n                     preprocessor=preprocessor,\n                     tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:37:29.565503Z","iopub.execute_input":"2024-05-16T02:37:29.566497Z","iopub.status.idle":"2024-05-16T02:37:29.570915Z","shell.execute_reply.started":"2024-05-16T02:37:29.566463Z","shell.execute_reply":"2024-05-16T02:37:29.569844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vqa2_dataset_val = VQADataset(questions=subset_val_questions,\n                     annotations=subset_val_annotations,\n                     preprocessor=preprocessor,\n                     tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:37:35.637420Z","iopub.execute_input":"2024-05-16T02:37:35.637834Z","iopub.status.idle":"2024-05-16T02:37:35.642851Z","shell.execute_reply.started":"2024-05-16T02:37:35.637804Z","shell.execute_reply":"2024-05-16T02:37:35.641592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vqa2_dataset[0].keys()","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:37:37.038599Z","iopub.execute_input":"2024-05-16T02:37:37.039287Z","iopub.status.idle":"2024-05-16T02:37:37.139347Z","shell.execute_reply.started":"2024-05-16T02:37:37.039256Z","shell.execute_reply":"2024-05-16T02:37:37.138383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vqa2_dataset_val[0].keys()","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:37:38.164679Z","iopub.execute_input":"2024-05-16T02:37:38.165658Z","iopub.status.idle":"2024-05-16T02:37:38.183251Z","shell.execute_reply.started":"2024-05-16T02:37:38.165621Z","shell.execute_reply":"2024-05-16T02:37:38.182404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ndef collate_fn(batch):\n  input_ids = [item['input_ids'] for item in batch]\n  #[print(len(item)) for item in input_ids]\n  pixel_values = [item['pixel_values'] for item in batch]\n  attention_mask = [item['attention_mask'] for item in batch]\n  token_type_ids = [item['token_type_ids'] for item in batch]\n  labels = [item['labels'] for item in batch]\n  \n  # # create padded pixel values and corresponding pixel mask\n  # encoding = processor.feature_extractor.pad_and_create_pixel_mask(pixel_values, return_tensors=\"pt\")\n  \n  # create new batch\n  batch = {}\n  batch['pixel_values'] = torch.stack(pixel_values)\n  batch['input_ids'] = torch.stack(input_ids)\n  batch['token_type_ids'] = torch.stack(token_type_ids)\n  batch['attention_mask'] = torch.stack(attention_mask)\n  # batch['pixel_mask'] = encoding['pixel_mask']\n  batch['labels'] = torch.stack(labels)\n  \n  return batch\n\ntrain_dataloader = DataLoader(vqa2_dataset, collate_fn=collate_fn, batch_size=4, shuffle=True,num_workers=4)\nval_dataloader = DataLoader(vqa2_dataset_val, collate_fn=collate_fn, batch_size=4,num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:37:40.873237Z","iopub.execute_input":"2024-05-16T02:37:40.874122Z","iopub.status.idle":"2024-05-16T02:37:40.883186Z","shell.execute_reply.started":"2024-05-16T02:37:40.874090Z","shell.execute_reply":"2024-05-16T02:37:40.882184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch = next(iter(train_dataloader))\nfor k,v in batch.items():\n  print(k, v.shape)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:37:42.903197Z","iopub.execute_input":"2024-05-16T02:37:42.903567Z","iopub.status.idle":"2024-05-16T02:37:43.496400Z","shell.execute_reply.started":"2024-05-16T02:37:42.903539Z","shell.execute_reply":"2024-05-16T02:37:43.494869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## PyTorch\nimport torch\nimport torch.nn as nn\nimport torch.utils.data as data\nimport torch.optim as optim\n\nfrom typing import Dict, List, Optional, Tuple","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:37:44.807488Z","iopub.execute_input":"2024-05-16T02:37:44.807839Z","iopub.status.idle":"2024-05-16T02:37:44.813382Z","shell.execute_reply.started":"2024-05-16T02:37:44.807806Z","shell.execute_reply":"2024-05-16T02:37:44.812315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define the Model","metadata":{}},{"cell_type":"code","source":"class MultimodalVQAModel(nn.Module):\n    def __init__(\n            self,\n            num_labels: int = len(config.id2label),\n            intermediate_dim: int = 512,\n            pretrained_text_name: str = 'bert-base-uncased',\n            pretrained_image_name: str = 'google/vit-base-patch16-224-in21k'):\n     \n        super(MultimodalVQAModel, self).__init__()\n        self.num_labels = num_labels\n        self.pretrained_text_name = pretrained_text_name\n        self.pretrained_image_name = pretrained_image_name\n        \n        self.text_encoder = AutoModel.from_pretrained(\n            self.pretrained_text_name,\n        )\n        self.image_encoder = AutoModel.from_pretrained(\n            self.pretrained_image_name,\n        )\n        self.fusion = nn.Sequential(\n            nn.Linear(self.text_encoder.config.hidden_size + self.image_encoder.config.hidden_size, intermediate_dim),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n        )\n        \n        self.classifier = nn.Linear(intermediate_dim, self.num_labels)\n        \n        self.criterion = nn.CrossEntropyLoss()\n    def forward(\n            self,\n            pixel_values: torch.FloatTensor,\n            input_ids: torch.LongTensor,\n            token_type_ids: Optional[torch.LongTensor] = None,\n            attention_mask: Optional[torch.LongTensor] = None,\n            labels: Optional[torch.LongTensor] = None):\n        \n        encoded_text = self.text_encoder(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            token_type_ids=token_type_ids,\n            return_dict=True,\n        )\n        encoded_image = self.image_encoder(\n            pixel_values=pixel_values,\n            return_dict=True,\n        )\n        fused_output = self.fusion(\n            torch.cat(\n                [\n                    encoded_text['pooler_output'],\n                    encoded_image['pooler_output'],\n                ],\n                dim=1\n            )\n        )\n        logits = self.classifier(fused_output)\n        out = {\n            \"logits\": logits\n        }\n        if labels is not None:\n            loss = self.criterion(logits, labels)\n            out[\"loss\"] = loss\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:37:47.354306Z","iopub.execute_input":"2024-05-16T02:37:47.354722Z","iopub.status.idle":"2024-05-16T02:37:47.368092Z","shell.execute_reply.started":"2024-05-16T02:37:47.354689Z","shell.execute_reply":"2024-05-16T02:37:47.366989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function for setting the seed\ndef set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\nset_seed(42)\n\n# Ensure that all operations are deterministic on GPU (if used) for reproducibility\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\ndevice = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\nprint(\"Using device\", device)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:37:49.068637Z","iopub.execute_input":"2024-05-16T02:37:49.069667Z","iopub.status.idle":"2024-05-16T02:37:49.158500Z","shell.execute_reply.started":"2024-05-16T02:37:49.069629Z","shell.execute_reply":"2024-05-16T02:37:49.157479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Structure","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModel","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:37:52.395974Z","iopub.execute_input":"2024-05-16T02:37:52.396844Z","iopub.status.idle":"2024-05-16T02:37:52.418832Z","shell.execute_reply.started":"2024-05-16T02:37:52.396814Z","shell.execute_reply":"2024-05-16T02:37:52.418024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = MultimodalVQAModel()\nmodel","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:37:53.751539Z","iopub.execute_input":"2024-05-16T02:37:53.752270Z","iopub.status.idle":"2024-05-16T02:38:01.401286Z","shell.execute_reply.started":"2024-05-16T02:37:53.752236Z","shell.execute_reply":"2024-05-16T02:38:01.400171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install peft","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:38:03.200015Z","iopub.execute_input":"2024-05-16T02:38:03.200684Z","iopub.status.idle":"2024-05-16T02:38:20.603576Z","shell.execute_reply.started":"2024-05-16T02:38:03.200650Z","shell.execute_reply":"2024-05-16T02:38:20.602142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from peft import get_peft_model, LoraConfig\n\nlora_config = LoraConfig(\n    r=16,  # Rank of the low-rank matrices\n    lora_alpha=16,  # Scaling factor\n    target_modules=[\"query\", \"value\"],  # Specify which layers to apply LoRA\n    lora_dropout=0.1  # Dropout rate\n)\n\nmodel = get_peft_model(model, lora_config)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:38:24.297746Z","iopub.execute_input":"2024-05-16T02:38:24.298191Z","iopub.status.idle":"2024-05-16T02:38:24.476544Z","shell.execute_reply.started":"2024-05-16T02:38:24.298150Z","shell.execute_reply":"2024-05-16T02:38:24.475711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:38:30.711307Z","iopub.execute_input":"2024-05-16T02:38:30.712176Z","iopub.status.idle":"2024-05-16T02:38:30.721150Z","shell.execute_reply.started":"2024-05-16T02:38:30.712142Z","shell.execute_reply":"2024-05-16T02:38:30.720230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Forward Pass","metadata":{}},{"cell_type":"code","source":"example = vqa2_dataset[0]\nprint(example.keys())\n# add batch dimension + move to GPU\nexample = {k: v.unsqueeze(0).to(device) for k,v in example.items()}\nprint(example)\n# forward pass\nmodel.to(device)\noutputs = model(**example)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:38:40.852104Z","iopub.execute_input":"2024-05-16T02:38:40.852565Z","iopub.status.idle":"2024-05-16T02:38:44.023729Z","shell.execute_reply.started":"2024-05-16T02:38:40.852530Z","shell.execute_reply":"2024-05-16T02:38:44.022881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = np.random.randint(len(config.id2label), size=5)\npreds = np.random.randint(len(config.id2label), size=5)\n\ndef showAnswers(ids):\n    print([config.id2label[id] for id in ids])\n\nshowAnswers(labels)\nshowAnswers(preds)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:38:45.526034Z","iopub.execute_input":"2024-05-16T02:38:45.527098Z","iopub.status.idle":"2024-05-16T02:38:45.534282Z","shell.execute_reply.started":"2024-05-16T02:38:45.527055Z","shell.execute_reply":"2024-05-16T02:38:45.533253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Number of parameters of the model","metadata":{}},{"cell_type":"code","source":"def countTrainableParameters(model):\n    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    print(\"No. of trainable parameters:\\t{0:,}\".format(num_params))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:38:48.374233Z","iopub.execute_input":"2024-05-16T02:38:48.375065Z","iopub.status.idle":"2024-05-16T02:38:48.382555Z","shell.execute_reply.started":"2024-05-16T02:38:48.375029Z","shell.execute_reply":"2024-05-16T02:38:48.381296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"countTrainableParameters(model) # For BERT-ViT model","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:38:49.691503Z","iopub.execute_input":"2024-05-16T02:38:49.692458Z","iopub.status.idle":"2024-05-16T02:38:49.701269Z","shell.execute_reply.started":"2024-05-16T02:38:49.692406Z","shell.execute_reply":"2024-05-16T02:38:49.700158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using Lightning module for training","metadata":{}},{"cell_type":"code","source":"!pip install pytorch-lightning","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:38:52.472521Z","iopub.execute_input":"2024-05-16T02:38:52.473244Z","iopub.status.idle":"2024-05-16T02:39:05.835517Z","shell.execute_reply.started":"2024-05-16T02:38:52.473215Z","shell.execute_reply":"2024-05-16T02:39:05.834200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n\nclass LightningMultimodalVQAModel(pl.LightningModule):\n    def __init__(self, model):\n        super().__init__()\n        self.model = model\n\n    def forward(self, pixel_values, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n        return self.model(pixel_values=pixel_values, input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask, labels=labels)\n\n    def training_step(self, batch, batch_idx):\n        output = self(**batch)\n        loss = output[\"loss\"]\n        self.log('train_loss', loss)\n        \n        # Compute additional metrics\n        preds = torch.argmax(output[\"logits\"], dim=1).detach().cpu().numpy()\n        labels = torch.argmax(batch[\"labels\"], dim=1).detach().cpu().numpy()\n\n        accuracy = accuracy_score(labels, preds)\n        precision = precision_score(labels, preds, average='weighted')\n        recall = recall_score(labels, preds, average='weighted')\n        f1 = f1_score(labels, preds, average='weighted')\n\n        self.log('train_accuracy', accuracy, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('train_precision', precision, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('train_recall', recall, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('train_f1', f1, on_step=True, on_epoch=True, prog_bar=True)\n        \n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        output = self(**batch)\n        loss = output[\"loss\"]\n        self.log('val_loss', loss)\n\n        # Compute additional metrics\n        preds = torch.argmax(output[\"logits\"], dim=1).detach().cpu().numpy()\n        labels = torch.argmax(batch[\"labels\"], dim=1).detach().cpu().numpy()\n\n        accuracy = accuracy_score(labels, preds)\n        precision = precision_score(labels, preds, average='weighted')\n        recall = recall_score(labels, preds, average='weighted')\n        f1 = f1_score(labels, preds, average='weighted')\n\n        self.log('val_accuracy', accuracy, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('val_precision', precision, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('val_recall', recall, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('val_f1', f1, on_step=True, on_epoch=True, prog_bar=True)\n\n    def test_step(self, batch, batch_idx):\n        output = self(**batch)\n        loss = output[\"loss\"]\n        self.log('test_loss', loss)\n\n        # Compute additional metrics\n        preds = torch.argmax(output[\"logits\"], dim=1).detach().cpu().numpy()\n        labels = torch.argmax(batch[\"labels\"], dim=1).detach().cpu().numpy()\n\n        accuracy = accuracy_score(labels, preds)\n        precision = precision_score(labels, preds, average='weighted')\n        recall = recall_score(labels, preds, average='weighted')\n        f1 = f1_score(labels, preds, average='weighted')\n\n        self.log('test_accuracy', accuracy, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('test_precision', precision, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('test_recall', recall, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('test_f1', f1, on_step=True, on_epoch=True, prog_bar=True)\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.AdamW(self.model.parameters(), lr=5e-5)\n        return optimizer","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:39:08.802683Z","iopub.execute_input":"2024-05-16T02:39:08.803082Z","iopub.status.idle":"2024-05-16T02:39:11.905914Z","shell.execute_reply.started":"2024-05-16T02:39:08.803048Z","shell.execute_reply":"2024-05-16T02:39:11.904863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score,f1_score\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:39:13.968460Z","iopub.execute_input":"2024-05-16T02:39:13.969284Z","iopub.status.idle":"2024-05-16T02:39:15.200332Z","shell.execute_reply.started":"2024-05-16T02:39:13.969253Z","shell.execute_reply":"2024-05-16T02:39:15.199415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize your model\nmultimodal_model = model\nlightning_model = LightningMultimodalVQAModel(multimodal_model)\n\n# Define the checkpoint callback\ncheckpoint_callback = ModelCheckpoint(\n    dirpath=\"my_model/checkpoint/\",\n    save_top_k=1,  # Save only the best model\n    verbose=True,\n    monitor=\"val_accuracy\",\n    mode=\"max\"\n)\n\n# Initialize the trainer\ntrainer = pl.Trainer(max_epochs=15,  callbacks=[checkpoint_callback])\n\n# Fit the model\ntrainer.fit(lightning_model, train_dataloader, val_dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:39:16.643093Z","iopub.execute_input":"2024-05-16T02:39:16.643530Z","iopub.status.idle":"2024-05-16T02:41:43.005552Z","shell.execute_reply.started":"2024-05-16T02:39:16.643498Z","shell.execute_reply":"2024-05-16T02:41:43.004617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %load_ext tensorboard\n# %tensorboard --logdir /kaggle/working/lightning_logs","metadata":{"execution":{"iopub.status.busy":"2024-05-14T17:28:56.782028Z","iopub.execute_input":"2024-05-14T17:28:56.782427Z","iopub.status.idle":"2024-05-14T17:29:05.339791Z","shell.execute_reply.started":"2024-05-14T17:28:56.782391Z","shell.execute_reply":"2024-05-14T17:29:05.338840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"# # Load the model from the checkpoint\n# checkpoint_path = \"/kaggle/input/vit-lora-roberta-15-epochs-15000/epoch13-step52500.ckpt\"\n# model1=MultimodalVQAModel()\n# model2 = get_peft_model(model1, lora_config)\n# lightning_model = LightningMultimodalVQAModel.load_from_checkpoint(checkpoint_path, model=model2)\n\n\n# # Place the model into evaluation mode and move it to the correct device\n# lightning_model = lightning_model.to(device)\n# lightning_model.eval()","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:42:17.842642Z","iopub.execute_input":"2024-05-16T02:42:17.843054Z","iopub.status.idle":"2024-05-16T02:42:20.611829Z","shell.execute_reply.started":"2024-05-16T02:42:17.843019Z","shell.execute_reply":"2024-05-16T02:42:20.610728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# For Validation","metadata":{}},{"cell_type":"code","source":"# id=56\n# showImage(False,id)\n# example = vqa2_dataset_val[id]\n# example = {k: v.unsqueeze(0).to(device) for k,v in example.items()}\n\n# # Forward pass\n# with torch.no_grad():\n#     input_ids = example[\"input_ids\"]\n#     print(input_ids.shape)\n#     outputs = lightning_model(**example)\n#     logits = outputs[\"logits\"]\n#     top2_values, top2_indices = logits.topk(2, dim=-1)\n#     predicted_classes = top2_indices.squeeze().tolist()\n#     print(\"Predicted answers:\", [config.id2label[predicted_class] for predicted_class in predicted_classes])","metadata":{"execution":{"iopub.status.busy":"2024-05-14T17:30:07.683796Z","iopub.execute_input":"2024-05-14T17:30:07.684634Z","iopub.status.idle":"2024-05-14T17:30:07.993082Z","shell.execute_reply.started":"2024-05-14T17:30:07.684589Z","shell.execute_reply":"2024-05-14T17:30:07.992115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# id=41\n# showImage(False,id)\n# example = vqa2_dataset_val[id]\n# example = {k: v.unsqueeze(0).to(device) for k,v in example.items()}\n\n# # Forward pass\n# with torch.no_grad():\n#     outputs = lightning_model(**example)\n#     logits = outputs[\"logits\"]\n#     top2_values, top2_indices = logits.topk(2, dim=-1)\n#     predicted_classes = top2_indices.squeeze().tolist()\n#     print(\"Predicted answers:\", [config.id2label[predicted_class] for predicted_class in predicted_classes])","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:42:36.104388Z","iopub.execute_input":"2024-05-16T02:42:36.104779Z","iopub.status.idle":"2024-05-16T02:42:36.496373Z","shell.execute_reply.started":"2024-05-16T02:42:36.104750Z","shell.execute_reply":"2024-05-16T02:42:36.495023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# id=90\n# showImage(False,id)\n# example = vqa2_dataset_val[id]\n# example = {k: v.unsqueeze(0).to(device) for k,v in example.items()}\n# example\n\n# # Forward pass\n# with torch.no_grad():\n#     outputs = lightning_model(**example)\n#     logits = outputs[\"logits\"]\n#     top2_values, top2_indices = logits.topk(2, dim=-1)\n#     predicted_classes = top2_indices.squeeze().tolist()\n#     print(\"Predicted answers:\", [config.id2label[predicted_class] for predicted_class in predicted_classes])","metadata":{"execution":{"iopub.status.busy":"2024-05-14T17:30:25.636325Z","iopub.execute_input":"2024-05-14T17:30:25.637285Z","iopub.status.idle":"2024-05-14T17:30:25.863430Z","shell.execute_reply.started":"2024-05-14T17:30:25.637251Z","shell.execute_reply":"2024-05-14T17:30:25.862447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# id=154\n# showImage(False,id)\n# example = vqa2_dataset_val[id]\n# example = {k: v.unsqueeze(0).to(device) for k,v in example.items()}\n\n# # Forward pass\n# with torch.no_grad():\n#     outputs = lightning_model(**example)\n#     logits = outputs[\"logits\"]\n#     top2_values, top2_indices = logits.topk(2, dim=-1)\n#     predicted_classes = top2_indices.squeeze().tolist()\n#     print(\"Predicted answers:\", [config.id2label[predicted_class] for predicted_class in predicted_classes])","metadata":{"execution":{"iopub.status.busy":"2024-05-14T17:30:36.604163Z","iopub.execute_input":"2024-05-14T17:30:36.604537Z","iopub.status.idle":"2024-05-14T17:30:36.879370Z","shell.execute_reply.started":"2024-05-14T17:30:36.604509Z","shell.execute_reply":"2024-05-14T17:30:36.878468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}