{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-18T16:55:08.288237Z","iopub.execute_input":"2024-05-18T16:55:08.288598Z","iopub.status.idle":"2024-05-18T16:55:09.320057Z","shell.execute_reply.started":"2024-05-18T16:55:08.288567Z","shell.execute_reply":"2024-05-18T16:55:09.319027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#this code loads the first 200 examples from the validation split of the \n#\"HuggingFaceM4/VQAv2\" dataset into the variable named dataset.\n\nfrom datasets import load_dataset\n\n# dataset = load_dataset(\"HuggingFaceM4/VQAv2\")\ndataset = load_dataset(\"HuggingFaceM4/VQAv2\", split=[\"train[:25%]\", \"validation[:25%]\"])\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-05-18T16:58:12.284171Z","iopub.execute_input":"2024-05-18T16:58:12.284700Z","iopub.status.idle":"2024-05-18T17:17:21.311308Z","shell.execute_reply.started":"2024-05-18T16:58:12.284667Z","shell.execute_reply":"2024-05-18T17:17:21.310396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Access the train split\ntrain_dataset = dataset[0]\n\n# Print the first row\nprint(train_dataset[0])","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:17:28.464626Z","iopub.execute_input":"2024-05-18T17:17:28.464952Z","iopub.status.idle":"2024-05-18T17:17:28.506981Z","shell.execute_reply.started":"2024-05-18T17:17:28.464926Z","shell.execute_reply":"2024-05-18T17:17:28.506098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset[0]['image']","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:17:33.871916Z","iopub.execute_input":"2024-05-18T17:17:33.872883Z","iopub.status.idle":"2024-05-18T17:17:33.976630Z","shell.execute_reply.started":"2024-05-18T17:17:33.872846Z","shell.execute_reply":"2024-05-18T17:17:33.975696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Access the validation split\nvalidation_dataset = dataset[1]\n\n# Print the first row\nprint(validation_dataset[0])","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:17:37.224212Z","iopub.execute_input":"2024-05-18T17:17:37.224596Z","iopub.status.idle":"2024-05-18T17:17:37.238604Z","shell.execute_reply.started":"2024-05-18T17:17:37.224562Z","shell.execute_reply":"2024-05-18T17:17:37.237741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_dataset[0]['image']","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:17:38.225910Z","iopub.execute_input":"2024-05-18T17:17:38.226714Z","iopub.status.idle":"2024-05-18T17:17:38.313602Z","shell.execute_reply.started":"2024-05-18T17:17:38.226679Z","shell.execute_reply":"2024-05-18T17:17:38.312728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing image","metadata":{}},{"cell_type":"code","source":"#Read only the Answer space from this model (labels and the config file)\nfrom transformers import ViltConfig\nconfig = ViltConfig.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:17:42.797334Z","iopub.execute_input":"2024-05-18T17:17:42.798004Z","iopub.status.idle":"2024-05-18T17:17:49.468324Z","shell.execute_reply.started":"2024-05-18T17:17:42.797971Z","shell.execute_reply":"2024-05-18T17:17:49.467604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(config.id2label)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:17:49.469812Z","iopub.execute_input":"2024-05-18T17:17:49.470270Z","iopub.status.idle":"2024-05-18T17:17:49.476838Z","shell.execute_reply.started":"2024-05-18T17:17:49.470239Z","shell.execute_reply":"2024-05-18T17:17:49.475737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:17:55.658266Z","iopub.execute_input":"2024-05-18T17:17:55.658621Z","iopub.status.idle":"2024-05-18T17:17:55.664603Z","shell.execute_reply.started":"2024-05-18T17:17:55.658592Z","shell.execute_reply":"2024-05-18T17:17:55.663654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(validation_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:17:56.311774Z","iopub.execute_input":"2024-05-18T17:17:56.312452Z","iopub.status.idle":"2024-05-18T17:17:56.318410Z","shell.execute_reply.started":"2024-05-18T17:17:56.312407Z","shell.execute_reply":"2024-05-18T17:17:56.317480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\n\ndef get_score(count: int) -> float:\n    return min(1.0, count / 3)\n\ndef add_labels_scores(annotation):\n\n    if(annotation['answers'] != None):\n        answers = annotation['answers']\n        answer_count = {}\n        for answer in answers:\n            answer_ = answer[\"answer\"]\n            answer_count[answer_] = answer_count.get(answer_, 0) + 1\n        labels = []\n        scores = []\n        for answer in answer_count:\n            if answer not in config.label2id:\n                continue\n            labels.append(config.label2id[answer])\n            score = get_score(answer_count[answer])\n            scores.append(score)\n        annotation['labels'] = labels\n        annotation['scores'] = scores\n \n    return annotation\n","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:17:59.037917Z","iopub.execute_input":"2024-05-18T17:17:59.038331Z","iopub.status.idle":"2024-05-18T17:17:59.046231Z","shell.execute_reply.started":"2024-05-18T17:17:59.038297Z","shell.execute_reply":"2024-05-18T17:17:59.045258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport numpy as np\nfrom IPython.display import display\n\n\n#This is not the subsetting, so we take the whole train, the subsetting happens way below\nnum_samples_to_display = len(train_dataset)\nsubset_train = train_dataset.select(range(num_samples_to_display))","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:18:02.536350Z","iopub.execute_input":"2024-05-18T17:18:02.536751Z","iopub.status.idle":"2024-05-18T17:18:02.546932Z","shell.execute_reply.started":"2024-05-18T17:18:02.536720Z","shell.execute_reply":"2024-05-18T17:18:02.546018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport numpy as np\nfrom IPython.display import display\n\n#This is not the subsetting, so we take the whole validation, the subsetting happens way below\nnum_samples_to_display = len(validation_dataset)\nsubset_val = validation_dataset.select(range(num_samples_to_display))","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:18:03.620235Z","iopub.execute_input":"2024-05-18T17:18:03.620616Z","iopub.status.idle":"2024-05-18T17:18:03.630875Z","shell.execute_reply.started":"2024-05-18T17:18:03.620585Z","shell.execute_reply":"2024-05-18T17:18:03.630019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def showImage(istrain=True, id=None):\n    if istrain:\n        data = subset_train\n    else:\n        data = subset_val\n    if id == None:\n        id = np.random.randint(len(data))\n    \n    modified_item = add_labels_scores(data[id])\n    #print(f\"Sample {id}: {modified_item}\\n\")\n    image = modified_item['image']\n\n    print(image)\n    display(image)\n\n    print(\"Question:\\t\", modified_item[\"question\"])\n    print(\"Answer:\\t\", modified_item[\"answers\"])\n    print(\"Labels:\\t\", modified_item[\"labels\"])\n    print(\"Scores:\\t\", modified_item[\"scores\"])\n    print(\"Scores for these labels:\\t\",[config.id2label[label] for label in modified_item[\"labels\"]])","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:18:06.120102Z","iopub.execute_input":"2024-05-18T17:18:06.120443Z","iopub.status.idle":"2024-05-18T17:18:06.127356Z","shell.execute_reply.started":"2024-05-18T17:18:06.120403Z","shell.execute_reply":"2024-05-18T17:18:06.126476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"showImage(True)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:18:08.546987Z","iopub.execute_input":"2024-05-18T17:18:08.547356Z","iopub.status.idle":"2024-05-18T17:18:08.676515Z","shell.execute_reply.started":"2024-05-18T17:18:08.547327Z","shell.execute_reply":"2024-05-18T17:18:08.675583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"showImage(False)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:18:09.078731Z","iopub.execute_input":"2024-05-18T17:18:09.079639Z","iopub.status.idle":"2024-05-18T17:18:09.293493Z","shell.execute_reply.started":"2024-05-18T17:18:09.079605Z","shell.execute_reply":"2024-05-18T17:18:09.292726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom PIL import Image\n\nclass VQADataset(torch.utils.data.Dataset):\n    \"\"\"VQA (v2) dataset.\"\"\"\n\n    def __init__(self, questions, annotations, preprocessor,tokenizer):\n        self.questions = questions\n        self.annotations = annotations\n        self.preprocessor = preprocessor\n        self.tokenizer=tokenizer\n\n    def __len__(self):\n        return len(self.annotations)\n\n    def __getitem__(self, idx):\n        # get image + text\n        annotations = self.annotations[idx]\n        questions = self.questions[idx]\n        image = annotations['image']\n        image = image.convert(\"RGB\")  # Explicitly convert the PIL Image object to RGB mode        \n        image = np.array(image)\n        text = questions['question']\n        \n        encoding = self.preprocessor(image, return_tensors=\"pt\")\n        encoded_text = self.tokenizer(\n            text=text,\n            padding='max_length',\n            max_length=24,\n            truncation=True,\n            return_tensors='pt',\n            return_token_type_ids=True,\n            return_attention_mask=True,\n        )\n\n        encoding [\"input_ids\"]= encoded_text['input_ids']\n        encoding [\"token_type_ids\"]= encoded_text['token_type_ids']\n        encoding [\"attention_mask\"]= encoded_text['attention_mask']\n\n\n        # remove batch dimension\n        for k,v in encoding.items():\n          encoding[k] = v.squeeze()\n        # add labels\n        labels = annotations['labels']\n        scores = annotations['scores']\n        # based on: https://github.com/dandelin/ViLT/blob/762fd3975c180db6fc88f577cf39549983fa373a/vilt/modules/objectives.py#L301\n        targets = torch.zeros(len(config.id2label))\n        for label, score in zip(labels, scores):\n              targets[label] = score\n        encoding[\"labels\"] = targets\n\n        return encoding\n","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:18:24.478405Z","iopub.execute_input":"2024-05-18T17:18:24.479324Z","iopub.status.idle":"2024-05-18T17:18:24.490357Z","shell.execute_reply.started":"2024-05-18T17:18:24.479292Z","shell.execute_reply":"2024-05-18T17:18:24.489284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Subsetting","metadata":{}},{"cell_type":"code","source":"import random\n\n# Specify the number of samples you want to use\nnum_samples = 15000\n\n# Randomly sample indices for our subset\nindices = random.sample(range(len(subset_train)), num_samples)\n\n# Create subset from the sampled indices\nsubset_questions = [{'question': subset_train[i]['question']} for i in indices]\nsubset_annotations = [add_labels_scores(subset_train[i]) for i in indices]","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:18:32.033662Z","iopub.execute_input":"2024-05-18T17:18:32.034033Z","iopub.status.idle":"2024-05-18T17:18:42.542655Z","shell.execute_reply.started":"2024-05-18T17:18:32.034003Z","shell.execute_reply":"2024-05-18T17:18:42.541824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Specify the number of samples you want to use\nnum_samples = 3000\n\n# Randomly sample indices for our subset\nval_indices = random.sample(range(len(subset_val)), num_samples)\nsubset_val_questions = [{'question': subset_val[i]['question']} for i in val_indices]\nsubset_val_annotations = [add_labels_scores(subset_val[i]) for i in val_indices]","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:18:48.031712Z","iopub.execute_input":"2024-05-18T17:18:48.032534Z","iopub.status.idle":"2024-05-18T17:19:17.923062Z","shell.execute_reply.started":"2024-05-18T17:18:48.032494Z","shell.execute_reply":"2024-05-18T17:19:17.922214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(subset_questions[0])\nprint(subset_annotations[0])\n     ","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:19:22.152833Z","iopub.execute_input":"2024-05-18T17:19:22.153523Z","iopub.status.idle":"2024-05-18T17:19:22.158724Z","shell.execute_reply.started":"2024-05-18T17:19:22.153483Z","shell.execute_reply":"2024-05-18T17:19:22.157779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(subset_val_questions[0])\nprint(subset_val_annotations[0])","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:19:22.955558Z","iopub.execute_input":"2024-05-18T17:19:22.956240Z","iopub.status.idle":"2024-05-18T17:19:22.961306Z","shell.execute_reply.started":"2024-05-18T17:19:22.956205Z","shell.execute_reply":"2024-05-18T17:19:22.960340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer,AutoFeatureExtractor\ntext='roberta-base'\nimage='microsoft/beit-base-patch16-224-pt22k-ft22k'\ntokenizer = AutoTokenizer.from_pretrained(text)\npreprocessor=AutoFeatureExtractor.from_pretrained(image)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:19:29.982861Z","iopub.execute_input":"2024-05-18T17:19:29.983639Z","iopub.status.idle":"2024-05-18T17:19:43.143616Z","shell.execute_reply.started":"2024-05-18T17:19:29.983608Z","shell.execute_reply":"2024-05-18T17:19:43.142692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vqa2_dataset = VQADataset(questions=subset_questions,\n                     annotations=subset_annotations,\n                     preprocessor=preprocessor,\n                     tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:19:49.631714Z","iopub.execute_input":"2024-05-18T17:19:49.632982Z","iopub.status.idle":"2024-05-18T17:19:49.640373Z","shell.execute_reply.started":"2024-05-18T17:19:49.632935Z","shell.execute_reply":"2024-05-18T17:19:49.639429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vqa2_dataset_val = VQADataset(questions=subset_val_questions,\n                     annotations=subset_val_annotations,\n                     preprocessor=preprocessor,\n                     tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:19:50.524497Z","iopub.execute_input":"2024-05-18T17:19:50.524870Z","iopub.status.idle":"2024-05-18T17:19:50.529746Z","shell.execute_reply.started":"2024-05-18T17:19:50.524838Z","shell.execute_reply":"2024-05-18T17:19:50.528608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vqa2_dataset[0].keys()","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:19:52.837622Z","iopub.execute_input":"2024-05-18T17:19:52.838449Z","iopub.status.idle":"2024-05-18T17:19:52.904409Z","shell.execute_reply.started":"2024-05-18T17:19:52.838409Z","shell.execute_reply":"2024-05-18T17:19:52.903490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vqa2_dataset_val[0].keys()","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:19:53.766068Z","iopub.execute_input":"2024-05-18T17:19:53.766423Z","iopub.status.idle":"2024-05-18T17:19:53.778924Z","shell.execute_reply.started":"2024-05-18T17:19:53.766392Z","shell.execute_reply":"2024-05-18T17:19:53.777993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ndef collate_fn(batch):\n  input_ids = [item['input_ids'] for item in batch]\n  #[print(len(item)) for item in input_ids]\n  pixel_values = [item['pixel_values'] for item in batch]\n  attention_mask = [item['attention_mask'] for item in batch]\n  token_type_ids = [item['token_type_ids'] for item in batch]\n  labels = [item['labels'] for item in batch]\n  \n  # # create padded pixel values and corresponding pixel mask\n  # encoding = processor.feature_extractor.pad_and_create_pixel_mask(pixel_values, return_tensors=\"pt\")\n  \n  # create new batch\n  batch = {}\n  batch['pixel_values'] = torch.stack(pixel_values)\n  batch['input_ids'] = torch.stack(input_ids)\n  batch['token_type_ids'] = torch.stack(token_type_ids)\n  batch['attention_mask'] = torch.stack(attention_mask)\n  # batch['pixel_mask'] = encoding['pixel_mask']\n  batch['labels'] = torch.stack(labels)\n  \n  return batch\n\ntrain_dataloader = DataLoader(vqa2_dataset, collate_fn=collate_fn, batch_size=4, shuffle=True,num_workers=4)\nval_dataloader = DataLoader(vqa2_dataset_val, collate_fn=collate_fn, batch_size=4,num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:19:59.829013Z","iopub.execute_input":"2024-05-18T17:19:59.829370Z","iopub.status.idle":"2024-05-18T17:19:59.838916Z","shell.execute_reply.started":"2024-05-18T17:19:59.829340Z","shell.execute_reply":"2024-05-18T17:19:59.837965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch = next(iter(train_dataloader))\nfor k,v in batch.items():\n  print(k, v.shape)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:20:07.612893Z","iopub.execute_input":"2024-05-18T17:20:07.613771Z","iopub.status.idle":"2024-05-18T17:20:08.218800Z","shell.execute_reply.started":"2024-05-18T17:20:07.613734Z","shell.execute_reply":"2024-05-18T17:20:08.217692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## PyTorch\nimport torch\nimport torch.nn as nn\nimport torch.utils.data as data\nimport torch.optim as optim\n\nfrom typing import Dict, List, Optional, Tuple","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:20:10.619194Z","iopub.execute_input":"2024-05-18T17:20:10.619594Z","iopub.status.idle":"2024-05-18T17:20:10.625367Z","shell.execute_reply.started":"2024-05-18T17:20:10.619555Z","shell.execute_reply":"2024-05-18T17:20:10.624253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define the Model","metadata":{}},{"cell_type":"code","source":"class MultimodalVQAModel(nn.Module):\n    def __init__(\n            self,\n            num_labels: int = len(config.id2label),\n            intermediate_dim: int = 512,\n            pretrained_text_name: str = 'roberta-base',\n            pretrained_image_name: str = 'microsoft/beit-base-patch16-224-pt22k-ft22k'):\n     \n        super(MultimodalVQAModel, self).__init__()\n        self.num_labels = num_labels\n        self.pretrained_text_name = pretrained_text_name\n        self.pretrained_image_name = pretrained_image_name\n        \n        self.text_encoder = AutoModel.from_pretrained(\n            self.pretrained_text_name,\n        )\n        self.image_encoder = AutoModel.from_pretrained(\n            self.pretrained_image_name,\n        )\n        self.fusion = nn.Sequential(\n            nn.Linear(self.text_encoder.config.hidden_size + self.image_encoder.config.hidden_size, intermediate_dim),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n        )\n        \n        self.classifier = nn.Linear(intermediate_dim, self.num_labels)\n        \n        self.criterion = nn.CrossEntropyLoss()\n    def forward(\n            self,\n            pixel_values: torch.FloatTensor,\n            input_ids: torch.LongTensor,\n            token_type_ids: Optional[torch.LongTensor] = None,\n            attention_mask: Optional[torch.LongTensor] = None,\n            labels: Optional[torch.LongTensor] = None):\n        \n        encoded_text = self.text_encoder(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            token_type_ids=token_type_ids,\n            return_dict=True,\n        )\n        encoded_image = self.image_encoder(\n            pixel_values=pixel_values,\n            return_dict=True,\n        )\n        fused_output = self.fusion(\n            torch.cat(\n                [\n                    encoded_text['pooler_output'],\n                    encoded_image['pooler_output'],\n                ],\n                dim=1\n            )\n        )\n        logits = self.classifier(fused_output)\n        out = {\n            \"logits\": logits\n        }\n        if labels is not None:\n            loss = self.criterion(logits, labels)\n            out[\"loss\"] = loss\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:20:15.285352Z","iopub.execute_input":"2024-05-18T17:20:15.286108Z","iopub.status.idle":"2024-05-18T17:20:15.297969Z","shell.execute_reply.started":"2024-05-18T17:20:15.286076Z","shell.execute_reply":"2024-05-18T17:20:15.296989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function for setting the seed\ndef set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\nset_seed(42)\n\n# Ensure that all operations are deterministic on GPU (if used) for reproducibility\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\ndevice = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\nprint(\"Using device\", device)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:20:19.096733Z","iopub.execute_input":"2024-05-18T17:20:19.097563Z","iopub.status.idle":"2024-05-18T17:20:19.181446Z","shell.execute_reply.started":"2024-05-18T17:20:19.097532Z","shell.execute_reply":"2024-05-18T17:20:19.180373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Structure","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModel","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:20:23.638246Z","iopub.execute_input":"2024-05-18T17:20:23.639235Z","iopub.status.idle":"2024-05-18T17:20:23.660544Z","shell.execute_reply.started":"2024-05-18T17:20:23.639198Z","shell.execute_reply":"2024-05-18T17:20:23.659800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = MultimodalVQAModel()\nmodel","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:20:24.760880Z","iopub.execute_input":"2024-05-18T17:20:24.761564Z","iopub.status.idle":"2024-05-18T17:20:31.925683Z","shell.execute_reply.started":"2024-05-18T17:20:24.761526Z","shell.execute_reply":"2024-05-18T17:20:31.924686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install peft","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:20:32.169224Z","iopub.execute_input":"2024-05-18T17:20:32.169845Z","iopub.status.idle":"2024-05-18T17:20:47.923561Z","shell.execute_reply.started":"2024-05-18T17:20:32.169809Z","shell.execute_reply":"2024-05-18T17:20:47.922239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from peft import get_peft_model, LoraConfig\n\nlora_config = LoraConfig(\n    r=16,  # Rank of the low-rank matrices\n    lora_alpha=16,  # Scaling factor\n    target_modules=[\"query\", \"value\"],  # Specify which layers to apply LoRA\n    lora_dropout=0.1  # Dropout rate\n)\n\nmodel = get_peft_model(model, lora_config)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:21:01.157020Z","iopub.execute_input":"2024-05-18T17:21:01.157410Z","iopub.status.idle":"2024-05-18T17:21:02.179742Z","shell.execute_reply.started":"2024-05-18T17:21:01.157376Z","shell.execute_reply":"2024-05-18T17:21:02.178897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:21:06.171867Z","iopub.execute_input":"2024-05-18T17:21:06.172537Z","iopub.status.idle":"2024-05-18T17:21:06.182051Z","shell.execute_reply.started":"2024-05-18T17:21:06.172503Z","shell.execute_reply":"2024-05-18T17:21:06.181120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Forward Pass","metadata":{}},{"cell_type":"code","source":"example = vqa2_dataset[0]\nprint(example.keys())\n# add batch dimension + move to GPU\nexample = {k: v.unsqueeze(0).to(device) for k,v in example.items()}\nprint(example)\n# forward pass\nmodel.to(device)\noutputs = model(**example)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:21:16.593566Z","iopub.execute_input":"2024-05-18T17:21:16.593924Z","iopub.status.idle":"2024-05-18T17:21:18.746133Z","shell.execute_reply.started":"2024-05-18T17:21:16.593896Z","shell.execute_reply":"2024-05-18T17:21:18.745173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = np.random.randint(len(config.id2label), size=5)\npreds = np.random.randint(len(config.id2label), size=5)\n\ndef showAnswers(ids):\n    print([config.id2label[id] for id in ids])\n\nshowAnswers(labels)\nshowAnswers(preds)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:21:20.466110Z","iopub.execute_input":"2024-05-18T17:21:20.466809Z","iopub.status.idle":"2024-05-18T17:21:20.475955Z","shell.execute_reply.started":"2024-05-18T17:21:20.466772Z","shell.execute_reply":"2024-05-18T17:21:20.474829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Number of parameters of the model","metadata":{}},{"cell_type":"code","source":"def countTrainableParameters(model):\n    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    print(\"No. of trainable parameters:\\t{0:,}\".format(num_params))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:21:24.594998Z","iopub.execute_input":"2024-05-18T17:21:24.595346Z","iopub.status.idle":"2024-05-18T17:21:24.600982Z","shell.execute_reply.started":"2024-05-18T17:21:24.595312Z","shell.execute_reply":"2024-05-18T17:21:24.599817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"countTrainableParameters(model) # For BERT-ViT model","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:21:25.953725Z","iopub.execute_input":"2024-05-18T17:21:25.954428Z","iopub.status.idle":"2024-05-18T17:21:25.963460Z","shell.execute_reply.started":"2024-05-18T17:21:25.954394Z","shell.execute_reply":"2024-05-18T17:21:25.962231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using Lightning module for training","metadata":{}},{"cell_type":"code","source":"!pip install pytorch-lightning","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:21:29.800287Z","iopub.execute_input":"2024-05-18T17:21:29.801005Z","iopub.status.idle":"2024-05-18T17:21:42.458567Z","shell.execute_reply.started":"2024-05-18T17:21:29.800972Z","shell.execute_reply":"2024-05-18T17:21:42.457272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom sklearn.metrics import accuracy_score, f1_score\n\nclass LightningMultimodalVQAModel(pl.LightningModule):\n    def __init__(self, model):\n        super().__init__()\n        self.model = model\n\n    def forward(self, pixel_values, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n        return self.model(pixel_values=pixel_values, input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask, labels=labels)\n\n    def training_step(self, batch, batch_idx):\n        output = self(**batch)\n        loss = output[\"loss\"]\n        self.log('train_loss', loss)\n        \n        # Compute additional metrics\n        preds = torch.argmax(output[\"logits\"], dim=1).detach().cpu().numpy()\n        labels = torch.argmax(batch[\"labels\"], dim=1).detach().cpu().numpy()\n\n        accuracy = accuracy_score(labels, preds)\n        precision = precision_score(labels, preds, average='weighted')\n        recall = recall_score(labels, preds, average='weighted')\n        f1 = f1_score(labels, preds, average='weighted')\n\n        self.log('train_accuracy', accuracy, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('train_precision', precision, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('train_recall', recall, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('train_f1', f1, on_step=True, on_epoch=True, prog_bar=True)\n        \n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        output = self(**batch)\n        loss = output[\"loss\"]\n        self.log('val_loss', loss)\n\n        # Compute additional metrics\n        preds = torch.argmax(output[\"logits\"], dim=1).detach().cpu().numpy()\n        labels = torch.argmax(batch[\"labels\"], dim=1).detach().cpu().numpy()\n\n        accuracy = accuracy_score(labels, preds)\n        precision = precision_score(labels, preds, average='weighted')\n        recall = recall_score(labels, preds, average='weighted')\n        f1 = f1_score(labels, preds, average='weighted')\n\n        self.log('val_accuracy', accuracy, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('val_precision', precision, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('val_recall', recall, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('val_f1', f1, on_step=True, on_epoch=True, prog_bar=True)\n\n    def test_step(self, batch, batch_idx):\n        output = self(**batch)\n        loss = output[\"loss\"]\n        self.log('test_loss', loss)\n\n        # Compute additional metrics\n        preds = torch.argmax(output[\"logits\"], dim=1).detach().cpu().numpy()\n        labels = torch.argmax(batch[\"labels\"], dim=1).detach().cpu().numpy()\n\n        accuracy = accuracy_score(labels, preds)\n        precision = precision_score(labels, preds, average='weighted')\n        recall = recall_score(labels, preds, average='weighted')\n        f1 = f1_score(labels, preds, average='weighted')\n\n        self.log('test_accuracy', accuracy, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('test_precision', precision, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('test_recall', recall, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('test_f1', f1, on_step=True, on_epoch=True, prog_bar=True)\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.AdamW(self.model.parameters(), lr=5e-5)\n        return optimizer","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:25:45.512797Z","iopub.execute_input":"2024-05-18T17:25:45.513517Z","iopub.status.idle":"2024-05-18T17:25:45.534307Z","shell.execute_reply.started":"2024-05-18T17:25:45.513481Z","shell.execute_reply":"2024-05-18T17:25:45.533298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score,f1_score, precision_score, recall_score\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:25:47.411946Z","iopub.execute_input":"2024-05-18T17:25:47.412292Z","iopub.status.idle":"2024-05-18T17:25:47.417119Z","shell.execute_reply.started":"2024-05-18T17:25:47.412265Z","shell.execute_reply":"2024-05-18T17:25:47.415799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize your model\nmultimodal_model = model\nlightning_model = LightningMultimodalVQAModel(multimodal_model)\n\n# Define the checkpoint callback\ncheckpoint_callback = ModelCheckpoint(\n    dirpath=\"my_model/checkpoint/\",\n    save_top_k=1,  # Save only the best model\n    verbose=True,\n    monitor=\"val_accuracy\",\n    mode=\"max\"\n)\n\n# Initialize the trainer\ntrainer = pl.Trainer(max_epochs=15,  callbacks=[checkpoint_callback])\n\n# Fit the model\ntrainer.fit(lightning_model, train_dataloader, val_dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:25:50.173665Z","iopub.execute_input":"2024-05-18T17:25:50.174072Z","iopub.status.idle":"2024-05-18T17:28:21.981028Z","shell.execute_reply.started":"2024-05-18T17:25:50.174037Z","shell.execute_reply":"2024-05-18T17:28:21.969363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %load_ext tensorboard\n# %tensorboard --logdir /kaggle/working/lightning_logs","metadata":{"execution":{"iopub.status.busy":"2024-05-14T17:28:56.782028Z","iopub.execute_input":"2024-05-14T17:28:56.782427Z","iopub.status.idle":"2024-05-14T17:29:05.339791Z","shell.execute_reply.started":"2024-05-14T17:28:56.782391Z","shell.execute_reply":"2024-05-14T17:29:05.338840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"# # Load the model from the checkpoint\n# checkpoint_path = \"/kaggle/input/vit-lora-roberta-15-epochs-15000/epoch13-step52500.ckpt\"\n# model1=MultimodalVQAModel()\n# model2 = get_peft_model(model1, lora_config)\n# lightning_model = LightningMultimodalVQAModel.load_from_checkpoint(checkpoint_path, model=model2)\n\n\n# # Place the model into evaluation mode and move it to the correct device\n# lightning_model = lightning_model.to(device)\n# lightning_model.eval()","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:42:17.842642Z","iopub.execute_input":"2024-05-16T02:42:17.843054Z","iopub.status.idle":"2024-05-16T02:42:20.611829Z","shell.execute_reply.started":"2024-05-16T02:42:17.843019Z","shell.execute_reply":"2024-05-16T02:42:20.610728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# For Validation","metadata":{}},{"cell_type":"code","source":"# id=56\n# showImage(False,id)\n# example = vqa2_dataset_val[id]\n# example = {k: v.unsqueeze(0).to(device) for k,v in example.items()}\n\n# # Forward pass\n# with torch.no_grad():\n#     input_ids = example[\"input_ids\"]\n#     print(input_ids.shape)\n#     outputs = lightning_model(**example)\n#     logits = outputs[\"logits\"]\n#     top2_values, top2_indices = logits.topk(2, dim=-1)\n#     predicted_classes = top2_indices.squeeze().tolist()\n#     print(\"Predicted answers:\", [config.id2label[predicted_class] for predicted_class in predicted_classes])","metadata":{"execution":{"iopub.status.busy":"2024-05-14T17:30:07.683796Z","iopub.execute_input":"2024-05-14T17:30:07.684634Z","iopub.status.idle":"2024-05-14T17:30:07.993082Z","shell.execute_reply.started":"2024-05-14T17:30:07.684589Z","shell.execute_reply":"2024-05-14T17:30:07.992115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# id=41\n# showImage(False,id)\n# example = vqa2_dataset_val[id]\n# example = {k: v.unsqueeze(0).to(device) for k,v in example.items()}\n\n# # Forward pass\n# with torch.no_grad():\n#     outputs = lightning_model(**example)\n#     logits = outputs[\"logits\"]\n#     top2_values, top2_indices = logits.topk(2, dim=-1)\n#     predicted_classes = top2_indices.squeeze().tolist()\n#     print(\"Predicted answers:\", [config.id2label[predicted_class] for predicted_class in predicted_classes])","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:42:36.104388Z","iopub.execute_input":"2024-05-16T02:42:36.104779Z","iopub.status.idle":"2024-05-16T02:42:36.496373Z","shell.execute_reply.started":"2024-05-16T02:42:36.104750Z","shell.execute_reply":"2024-05-16T02:42:36.495023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# id=90\n# showImage(False,id)\n# example = vqa2_dataset_val[id]\n# example = {k: v.unsqueeze(0).to(device) for k,v in example.items()}\n# example\n\n# # Forward pass\n# with torch.no_grad():\n#     outputs = lightning_model(**example)\n#     logits = outputs[\"logits\"]\n#     top2_values, top2_indices = logits.topk(2, dim=-1)\n#     predicted_classes = top2_indices.squeeze().tolist()\n#     print(\"Predicted answers:\", [config.id2label[predicted_class] for predicted_class in predicted_classes])","metadata":{"execution":{"iopub.status.busy":"2024-05-14T17:30:25.636325Z","iopub.execute_input":"2024-05-14T17:30:25.637285Z","iopub.status.idle":"2024-05-14T17:30:25.863430Z","shell.execute_reply.started":"2024-05-14T17:30:25.637251Z","shell.execute_reply":"2024-05-14T17:30:25.862447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# id=154\n# showImage(False,id)\n# example = vqa2_dataset_val[id]\n# example = {k: v.unsqueeze(0).to(device) for k,v in example.items()}\n\n# # Forward pass\n# with torch.no_grad():\n#     outputs = lightning_model(**example)\n#     logits = outputs[\"logits\"]\n#     top2_values, top2_indices = logits.topk(2, dim=-1)\n#     predicted_classes = top2_indices.squeeze().tolist()\n#     print(\"Predicted answers:\", [config.id2label[predicted_class] for predicted_class in predicted_classes])","metadata":{"execution":{"iopub.status.busy":"2024-05-14T17:30:36.604163Z","iopub.execute_input":"2024-05-14T17:30:36.604537Z","iopub.status.idle":"2024-05-14T17:30:36.879370Z","shell.execute_reply.started":"2024-05-14T17:30:36.604509Z","shell.execute_reply":"2024-05-14T17:30:36.878468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}